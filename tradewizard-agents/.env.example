# ============================================================================
# Market Intelligence Engine Configuration
# ============================================================================
# This file contains all configuration options for the Market Intelligence Engine.
# Copy this file to .env and fill in your actual values.

# ============================================================================
# Polymarket API Configuration
# ============================================================================
# Configure connection to Polymarket's prediction market APIs
POLYMARKET_GAMMA_API_URL=https://gamma-api.polymarket.com
POLYMARKET_CLOB_API_URL=https://clob.polymarket.com
POLYMARKET_RATE_LIMIT_BUFFER=80  # Use 80% of rate limit (0-100)
POLYMARKET_POLITICS_TAG_ID=2     # Tag ID for political events filtering

# ============================================================================
# Enhanced Event-Based Polymarket Configuration
# ============================================================================
# Configure event-based analysis using Polymarket's events API endpoint
# with proper tag filtering and multi-market analysis capabilities

# Event API Configuration
POLYMARKET_EVENTS_API_ENDPOINT=/events          # Events API endpoint path
POLYMARKET_INCLUDE_RELATED_TAGS=true            # Include related tags in event queries
POLYMARKET_MAX_EVENTS_PER_DISCOVERY=20          # Maximum events per discovery request
POLYMARKET_MAX_MARKETS_PER_EVENT=50             # Maximum markets per event to process
POLYMARKET_DEFAULT_SORT_BY=volume24hr           # Default sorting: volume24hr, liquidity, competitive, marketCount

# Multi-Market Analysis Configuration
POLYMARKET_ENABLE_CROSS_MARKET_ANALYSIS=true    # Enable cross-market correlation analysis
POLYMARKET_CORRELATION_THRESHOLD=0.3            # Minimum correlation coefficient threshold
POLYMARKET_ARBITRAGE_THRESHOLD=0.05             # Minimum arbitrage opportunity threshold (5%)

# Rate Limiting Configuration for Events API
POLYMARKET_EVENTS_API_RATE_LIMIT=500            # Events API specific rate limit
POLYMARKET_MAX_REQUESTS_PER_MINUTE=60           # Maximum requests per minute
POLYMARKET_RATE_LIMIT_WINDOW_MS=60000           # Rate limit window in milliseconds (1 minute)

# Caching Configuration
POLYMARKET_EVENT_CACHE_TTL=300                  # Event cache TTL in seconds (5 minutes)
POLYMARKET_MARKET_CACHE_TTL=300                 # Market cache TTL in seconds (5 minutes)
POLYMARKET_TAG_CACHE_TTL=3600                   # Tag cache TTL in seconds (1 hour)
POLYMARKET_CORRELATION_CACHE_TTL=1800           # Correlation cache TTL in seconds (30 minutes)

# Feature Flags for Enhanced Event Discovery
POLYMARKET_ENABLE_EVENT_BASED_KEYWORDS=true     # Enable event-level keyword extraction
POLYMARKET_ENABLE_MULTI_MARKET_ANALYSIS=true    # Enable multi-market analysis within events
POLYMARKET_ENABLE_CROSS_MARKET_CORRELATION=true # Enable cross-market correlation detection
POLYMARKET_ENABLE_ARBITRAGE_DETECTION=true      # Enable arbitrage opportunity detection
POLYMARKET_ENABLE_EVENT_LEVEL_INTELLIGENCE=true # Enable event-level intelligence gathering
POLYMARKET_ENABLE_ENHANCED_EVENT_DISCOVERY=true # Enable enhanced event discovery modes
POLYMARKET_ENABLE_MULTI_MARKET_FILTERING=true   # Enable multi-market filtering options
POLYMARKET_ENABLE_EVENT_RANKING_ALGORITHM=true  # Enable advanced event ranking algorithm
POLYMARKET_ENABLE_CROSS_MARKET_OPPORTUNITIES=true # Enable cross-market opportunity detection

# Error Handling and Resilience Configuration
POLYMARKET_MAX_RETRIES=3                        # Maximum retry attempts for API calls
POLYMARKET_CIRCUIT_BREAKER_THRESHOLD=5          # Circuit breaker failure threshold
POLYMARKET_FALLBACK_TO_CACHE=true               # Enable fallback to cached data
POLYMARKET_ENABLE_GRACEFUL_DEGRADATION=true     # Enable graceful degradation on partial failures

# Analysis Configuration
POLYMARKET_KEYWORD_EXTRACTION_MODE=event_priority # Keyword extraction mode: event_priority, market_priority, balanced
POLYMARKET_CORRELATION_ANALYSIS_DEPTH=basic     # Correlation analysis depth: basic, advanced, comprehensive
POLYMARKET_RISK_ASSESSMENT_LEVEL=moderate       # Risk assessment level: conservative, moderate, aggressive

# ============================================================================
# Environment-Specific Event API Configuration
# ============================================================================
# Configure different settings for development, staging, and production environments
# The system will automatically use the appropriate configuration based on NODE_ENV

# Development Environment Configuration (NODE_ENV=development)
POLYMARKET_DEV_EVENTS_API_RATE_LIMIT=100        # Lower rate limit for development
POLYMARKET_DEV_MAX_REQUESTS_PER_MINUTE=30       # Conservative request rate for development
POLYMARKET_DEV_EVENT_CACHE_TTL=60               # Shorter cache TTL for development (1 minute)
POLYMARKET_DEV_ENABLE_DEBUG_LOGGING=true        # Enable debug logging in development
POLYMARKET_DEV_ENABLE_MOCK_DATA=false           # Enable mock data for testing (optional)

# Staging Environment Configuration (NODE_ENV=staging)
POLYMARKET_STAGING_EVENTS_API_RATE_LIMIT=300    # Medium rate limit for staging
POLYMARKET_STAGING_MAX_REQUESTS_PER_MINUTE=45   # Medium request rate for staging
POLYMARKET_STAGING_EVENT_CACHE_TTL=180          # Medium cache TTL for staging (3 minutes)
POLYMARKET_STAGING_ENABLE_DEBUG_LOGGING=false   # Disable debug logging in staging
POLYMARKET_STAGING_ENABLE_MOCK_DATA=false       # Disable mock data in staging

# Production Environment Configuration (NODE_ENV=production)
POLYMARKET_PROD_EVENTS_API_RATE_LIMIT=500       # Full rate limit for production
POLYMARKET_PROD_MAX_REQUESTS_PER_MINUTE=60      # Full request rate for production
POLYMARKET_PROD_EVENT_CACHE_TTL=300             # Longer cache TTL for production (5 minutes)
POLYMARKET_PROD_ENABLE_DEBUG_LOGGING=false      # Disable debug logging in production
POLYMARKET_PROD_ENABLE_MOCK_DATA=false          # Disable mock data in production

# ============================================================================
# LLM Configuration
# ============================================================================
# The engine supports two modes:
#
# 1. SINGLE-PROVIDER MODE (Budget-Friendly):
#    - Set LLM_SINGLE_PROVIDER to 'openai', 'anthropic', or 'google'
#    - Configure only that provider's API key and model
#    - All agents use the same LLM with different prompts
#    - Lower cost, simpler API key management
#
# 2. MULTI-PROVIDER MODE (Optimal Quality, Default):
#    - Leave LLM_SINGLE_PROVIDER unset or commented out
#    - Configure multiple providers
#    - Each agent uses a different LLM optimized for its task
#    - Higher cost but better quality recommendations

# ----------------------------------------------------------------------------
# Single-Provider Mode Example (Uncomment to enable)
# ----------------------------------------------------------------------------
# LLM_SINGLE_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# OPENAI_DEFAULT_MODEL=gpt-4o-mini

# ----------------------------------------------------------------------------
# Multi-Provider Mode (Default - Configure all providers you want to use)
# ----------------------------------------------------------------------------
# OpenAI Configuration (used for Market Microstructure Agent in multi-provider mode)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_DEFAULT_MODEL=gpt-4-turbo

# Anthropic Configuration (used for Risk Assessment Agent in multi-provider mode)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_DEFAULT_MODEL=claude-3-sonnet-20240229

# Google Configuration (used for Probability Baseline Agent in multi-provider mode)
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_DEFAULT_MODEL=gemini-1.5-flash

# ----------------------------------------------------------------------------
# Amazon Nova Configuration (AWS Bedrock)
# ----------------------------------------------------------------------------
# Amazon Nova is AWS's family of foundation models available through Bedrock
# Offers competitive pricing and performance for various AI tasks
# Requires AWS credentials with bedrock:InvokeModel permissions

# AWS Credentials (required for Nova)
AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
AWS_REGION=us-east-1

# Nova Model Selection
# Available models:
#   Nova v1 Models (Original):
#   - amazon.nova-micro-v1:0  (Lightweight, cost-efficient: $0.000035/1K input, $0.00014/1K output)
#   - amazon.nova-lite-v1:0   (Balanced performance: $0.00006/1K input, $0.00024/1K output)
#   - amazon.nova-pro-v1:0    (Complex reasoning: $0.0008/1K input, $0.0032/1K output)
#   Nova 2 Models (December 2025 - Latest):
#   - global.amazon.nova-2-lite-v1:0  (Fast reasoning, 1M context: $0.30/1M input, $2.50/1M output)
#   - global.amazon.nova-2-pro-v1:0   (Preview - Most intelligent, 1M context)
NOVA_MODEL_NAME=global.amazon.nova-2-lite-v1:0

# Nova Model Parameters (optional)
NOVA_TEMPERATURE=0.7              # Sampling temperature (0.0-1.0)
NOVA_MAX_TOKENS=2048              # Maximum output tokens
NOVA_TOP_P=0.9                    # Nucleus sampling parameter

# Multi-Provider Mode with Nova
# To use Nova for specific agents, set agent-specific environment variables:
# NEWS_AGENT_PROVIDER=nova
# NEWS_AGENT_MODEL=amazon.nova-pro-v1:0
# POLLING_AGENT_PROVIDER=nova
# POLLING_AGENT_MODEL=amazon.nova-lite-v1:0

# Single-Provider Mode with Nova
# To use Nova for all agents, uncomment:
# LLM_SINGLE_PROVIDER=nova

# ============================================================================
# Opik Configuration (Observability & Tracing)
# ============================================================================
# Opik provides LLM tracing, debugging, and cost tracking
# Supports both cloud (https://www.comet.com/opik) and self-hosted deployments

# Cloud Opik (default)
OPIK_API_KEY=your_opik_api_key_here
OPIK_PROJECT_NAME=market-intelligence-engine
OPIK_WORKSPACE=default
OPIK_TRACK_COSTS=true

# Self-Hosted Opik (uncomment if using self-hosted)
# OPIK_BASE_URL=http://localhost:5000
# OPIK_PROJECT_NAME=market-intelligence-engine
# OPIK_TRACK_COSTS=true

# Optional: Add tags to all traces (comma-separated)
# OPIK_TAGS=production,v1.0,debate-protocol

# ============================================================================
# Agent Configuration
# ============================================================================
# Configure agent behavior and thresholds
AGENT_TIMEOUT_MS=10000           # Maximum time per agent in milliseconds
MIN_AGENTS_REQUIRED=2            # Minimum agents needed for consensus

# ============================================================================
# Consensus Configuration
# ============================================================================
# Configure consensus calculation and trade recommendation thresholds
MIN_EDGE_THRESHOLD=0.05                # Minimum edge to recommend trade (5%)
HIGH_DISAGREEMENT_THRESHOLD=0.15       # Disagreement index threshold (15%)

# ============================================================================
# Logging Configuration
# ============================================================================
# Configure system logging behavior
LOG_LEVEL=info                        # Options: debug, info, warn, error
AUDIT_TRAIL_RETENTION_DAYS=30         # Days to retain audit logs

# ============================================================================
# LangGraph Configuration
# ============================================================================
# Configure the LangGraph workflow engine
LANGGRAPH_CHECKPOINTER=memory         # Options: memory, sqlite, postgres
LANGGRAPH_RECURSION_LIMIT=25          # Maximum graph execution depth
LANGGRAPH_STREAM_MODE=values          # Options: values, updates

# Checkpointer Options:
# - memory: In-memory (development, no persistence)
# - sqlite: File-based persistence (production)
# - postgres: Database persistence (production, requires DB setup)

# ============================================================================
# Supabase Configuration (Automated Market Monitor)
# ============================================================================
# Configure connection to Supabase PostgreSQL for persistent storage
# Required for the Automated Market Monitor service

SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your_supabase_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# ============================================================================
# Automated Market Monitor Configuration
# ============================================================================
# Configure the background service that monitors and analyzes markets

# Scheduling
ANALYSIS_INTERVAL_HOURS=24           # How often to discover and analyze markets
UPDATE_INTERVAL_HOURS=24             # How often to update existing markets
MAX_MARKETS_PER_CYCLE=3              # Maximum markets to analyze per cycle

# API Quotas (daily limits to stay within free tiers)
NEWS_API_DAILY_QUOTA=100             # NewsAPI daily request limit (legacy)
NEWSDATA_DAILY_QUOTA=20000           # NewsData.io daily request limit
TWITTER_API_DAILY_QUOTA=500          # Twitter API daily request limit
REDDIT_API_DAILY_QUOTA=60            # Reddit API daily request limit

# ============================================================================
# News API Configuration
# ============================================================================
# Configure news data sources for market analysis

# Legacy NewsAPI Configuration (will be deprecated)
NEWS_API_PROVIDER=newsapi            # Options: newsapi, newsdata
NEWS_API_KEY=your_newsapi_key_here
NEWS_API_CACHE_TTL=900               # Cache TTL in seconds (15 minutes)
NEWS_API_MAX_ARTICLES=50             # Maximum articles per request

# NewsData.io Configuration (recommended)
NEWSDATA_API_KEY=your_newsdata_api_key_here
NEWSDATA_ENABLED=true                # Enable NewsData.io integration
NEWSDATA_CACHE_TTL_LATEST=900        # Latest news cache TTL (15 minutes)
NEWSDATA_CACHE_TTL_CRYPTO=600        # Crypto news cache TTL (10 minutes)
NEWSDATA_CACHE_TTL_MARKET=600        # Market news cache TTL (10 minutes)
NEWSDATA_CACHE_TTL_ARCHIVE=3600      # Archive news cache TTL (1 hour)
NEWSDATA_RATE_LIMIT_REQUESTS=1800    # Requests per 15-minute window
NEWSDATA_RATE_LIMIT_WINDOW_MS=900000 # Rate limit window (15 minutes)
NEWSDATA_CIRCUIT_BREAKER_ENABLED=true
NEWSDATA_CIRCUIT_BREAKER_THRESHOLD=5
NEWSDATA_CIRCUIT_BREAKER_TIMEOUT=60000

# ============================================================================
# News Migration Configuration
# ============================================================================
# Configure migration from NewsAPI to NewsData.io

# Migration Control
NEWS_MIGRATION_ENABLED=false         # Enable migration mode
NEWS_MIGRATION_STRATEGY=newsapi-only # Options: newsapi-only, newsdata-only, dual-provider, gradual-migration
NEWS_MIGRATION_PERCENTAGE=0          # Percentage of requests to route to NewsData.io (0-100)
NEWS_MIGRATION_FALLBACK_ENABLED=true # Enable fallback between providers
NEWS_MIGRATION_PRESERVE_CACHE=true   # Preserve cache during migration
NEWS_MIGRATION_ROLLBACK_ENABLED=true # Enable rollback capability

# Compatibility Settings
NEWS_COMPATIBILITY_MAP_FORMAT=true   # Map NewsData.io responses to NewsAPI format
NEWS_COMPATIBILITY_EXTENDED_FIELDS=false # Include additional NewsData.io fields
NEWS_COMPATIBILITY_DEFAULT_AUTHOR=Unknown # Default author when not available
NEWS_COMPATIBILITY_DEFAULT_SOURCE=Unknown Source # Default source when not available

# Service Configuration
HEALTH_CHECK_PORT=3000               # Port for health check endpoint
ENABLE_MANUAL_TRIGGERS=true          # Allow manual analysis triggers

# ============================================================================
# Agent Autonomous Mode Configuration
# ============================================================================
# Autonomous mode is now ENABLED BY DEFAULT (recommended)
# Agents use LangChain's tool-calling capabilities to autonomously fetch and
# analyze data during execution, providing higher quality analysis.
#
# To disable autonomous mode for a specific agent, set its variable to false:
# BREAKING_NEWS_AGENT_AUTONOMOUS=false
# MEDIA_SENTIMENT_AGENT_AUTONOMOUS=false
# MARKET_MICROSTRUCTURE_AGENT_AUTONOMOUS=false
# POLLING_AGENT_AUTONOMOUS=false

# Breaking News Agent Configuration
BREAKING_NEWS_AGENT_AUTONOMOUS=true          # Autonomous mode enabled by default
BREAKING_NEWS_AGENT_MAX_TOOL_CALLS=5         # Max tools per analysis
BREAKING_NEWS_AGENT_TIMEOUT=45000            # Timeout in milliseconds
BREAKING_NEWS_AGENT_CACHE_ENABLED=true       # Enable result caching
BREAKING_NEWS_AGENT_FALLBACK_TO_BASIC=true   # Fallback on error

# Media Sentiment Agent Configuration
MEDIA_SENTIMENT_AGENT_AUTONOMOUS=true        # Autonomous mode enabled by default
MEDIA_SENTIMENT_AGENT_MAX_TOOL_CALLS=5
MEDIA_SENTIMENT_AGENT_TIMEOUT=45000
MEDIA_SENTIMENT_AGENT_CACHE_ENABLED=true
MEDIA_SENTIMENT_AGENT_FALLBACK_TO_BASIC=true

# Market Microstructure Agent Configuration
MARKET_MICROSTRUCTURE_AGENT_AUTONOMOUS=true  # Autonomous mode enabled by default
MARKET_MICROSTRUCTURE_AGENT_MAX_TOOL_CALLS=5
MARKET_MICROSTRUCTURE_AGENT_TIMEOUT=45000
MARKET_MICROSTRUCTURE_AGENT_CACHE_ENABLED=true
MARKET_MICROSTRUCTURE_AGENT_FALLBACK_TO_BASIC=true

# Polling Agent Configuration
POLLING_AGENT_AUTONOMOUS=true                # Autonomous mode enabled by default
POLLING_AGENT_MAX_TOOL_CALLS=5
POLLING_AGENT_TIMEOUT=45000
POLLING_AGENT_CACHE_ENABLED=true
POLLING_AGENT_FALLBACK_TO_BASIC=true

# ============================================================================
# Agent Memory System Configuration
# ============================================================================
# Configure the agent memory system that enables agents to access and reference
# their previous analysis outputs for the same market, creating a closed-loop
# feedback system for improved analysis quality and consistency over time.

# Feature Flag (Master Switch)
MEMORY_SYSTEM_ENABLED=false          # Enable/disable the entire memory system (default: false)

# Memory Retrieval Configuration
MEMORY_SYSTEM_MAX_SIGNALS_PER_AGENT=3    # Maximum historical signals per agent-market (1-10, default: 3)
MEMORY_SYSTEM_QUERY_TIMEOUT_MS=5000      # Query timeout in milliseconds (default: 5000)
MEMORY_SYSTEM_RETRY_ATTEMPTS=3           # Number of retry attempts for rate limits (0-5, default: 3)

# Configuration Guidelines:
# - Development: ENABLED=true, MAX_SIGNALS=5, TIMEOUT=10000, RETRIES=3
# - Production: ENABLED=true, MAX_SIGNALS=3, TIMEOUT=5000, RETRIES=3
# - Disabled: ENABLED=false (other settings ignored)
#
# See src/database/MEMORY_SYSTEM_CONFIG.md for detailed documentation

# ============================================================================
# Human-Readable Timestamp Configuration
# ============================================================================
# Configure timestamp formatting for AI agent consumption
# When enabled, timestamps are converted to human-readable format (e.g., "2 hours ago", "January 15, 2024 at 3:30 PM EST")
# When disabled, timestamps are returned in ISO 8601 format

# Enable/disable human-readable timestamp formatting for AI agents
# Default: true (enabled for new deployments)
ENABLE_HUMAN_READABLE_TIMESTAMPS=true

# Timezone for absolute timestamp formatting
# Default: America/New_York (Eastern Time)
# All timestamps are converted to this timezone for consistency with US political events
TIMESTAMP_TIMEZONE=America/New_York

# Threshold in days for switching from relative to absolute time format
# Timestamps older than this threshold use absolute format (e.g., "January 15, 2024 at 3:30 PM EST")
# Timestamps newer than this threshold use relative format (e.g., "2 hours ago")
# Default: 7 days
RELATIVE_TIME_THRESHOLD_DAYS=7
